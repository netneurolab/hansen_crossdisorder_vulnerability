"""
This script runs the multilinear models and dominance analysis,
then compares model fits. Analyses here correspond to Figures
1 and 2 in the manuscript.
Note that running the null iterations takes time.
"""

import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from scipy.stats import zscore, pearsonr
import seaborn as sns
import matplotlib.pyplot as plt
from netneurotools import stats, datasets, utils
from scipy.spatial.distance import squareform, pdist
from matplotlib.colors import ListedColormap
from sklearn.decomposition import PCA

# set path to directory
path = "C:/Users/justi/OneDrive - McGill University/MisicLab/proj_biology_disease/github/hansen_crossdisorder_vulnerability/"


def get_reg_r_sq(X, y):
    lin_reg = LinearRegression()
    lin_reg.fit(X, y)
    yhat = lin_reg.predict(X)
    SS_Residual = sum((y - yhat) ** 2)
    SS_Total = sum((y - np.mean(y)) ** 2)
    r_squared = 1 - (float(SS_Residual)) / SS_Total
    adjusted_r_squared = 1 - (1 - r_squared) * \
        (len(y) - 1) / (len(y) - X.shape[1] - 1)
    return adjusted_r_squared


def cv_slr_distance_dependent(X, y, coords, train_pct=.75, metric='rsq'):
    '''
    cross validates linear regression model using distance-dependent method.
    X = n x p matrix of input variables
    y = n x 1 matrix of output variable
    coords = n x 3 coordinates of each observation
    train_pct (between 0 and 1), percent of observations in training set
    metric = {'rsq', 'corr'}
    '''

    P = squareform(pdist(coords, metric="euclidean"))
    train_metric = []
    test_metric = []

    for i in range(len(y)):
        distances = P[i, :]  # for every node
        idx = np.argsort(distances)

        train_idx = idx[:int(np.floor(train_pct * len(coords)))]
        test_idx = idx[int(np.floor(train_pct * len(coords))):]

        mdl = LinearRegression()
        mdl.fit(X[train_idx, :], y[train_idx])
        if metric == 'rsq':
            # get r^2 of train set
            train_metric.append(get_reg_r_sq(X[train_idx, :], y[train_idx]))

        elif metric == 'corr':
            rho, _ = pearsonr(mdl.predict(X[train_idx, :]), y[train_idx])
            train_metric.append(rho)

        yhat = mdl.predict(X[test_idx, :])
        if metric == 'rsq':
            # get r^2 of test set
            SS_Residual = sum((y[test_idx] - yhat) ** 2)
            SS_Total = sum((y[test_idx] - np.mean(y[test_idx])) ** 2)
            r_squared = 1 - (float(SS_Residual)) / SS_Total
            adjusted_r_squared = 1-(1-r_squared)*((len(y[test_idx]) - 1) /
                                                  (len(y[test_idx]) -
                                                   X.shape[1]-1))
            test_metric.append(adjusted_r_squared)

        elif metric == 'corr':
            rho, _ = pearsonr(yhat, y[test_idx])
            test_metric.append(rho)

    return train_metric, test_metric


def get_perm_p(emp, null):
    return (1 + sum(abs(null - np.mean(null))
                    > abs(emp - np.mean(null)))) / (len(null) + 1)


def get_boot_ci(X, y, n):
    nnodes = len(y)
    bootsamp = np.zeros((n, ))
    for iter in range(n):
        sample = np.random.choice(range(nnodes), nnodes)
        bootsamp[iter] = get_reg_r_sq(X[sample, :], y[sample])
    ci = np.percentile(bootsamp, [100 * (1 - 0.95) / 2, 100 * (1 - (1 - 0.95) / 2)])
    return ci[0], ci[1], bootsamp

def compare_models(X1, X2, y, spins, nspins):
    emp = get_reg_r_sq(X1, y) - get_reg_r_sq(X2, y)
    null = np.zeros((nspins, ))
    for s in range(nspins):
        null[s] = get_reg_r_sq(X1[spins[:, s], :], y) - \
                  get_reg_r_sq(X2[spins[:, s], :], y)
    return emp, null, get_perm_p(emp, null)


"""
load
"""

# disorder maps + predictors
ct = np.genfromtxt(path+'data/enigma_ct.csv', delimiter=',')
bio = np.genfromtxt(path+'data/local_biol_predictors.csv', delimiter=',')
conn = np.genfromtxt(path+'data/global_conn_predictors.csv', delimiter=',')
conn_bin = np.genfromtxt(path+'data/global_conn_predictors_bin.csv', delimiter=',')
conn_fc = np.genfromtxt(path+'data/global_conn_predictors_fc.csv', delimiter=',')
temp = np.genfromtxt(path+'data/temporal_predictors.csv', delimiter=',')

bio_predictor_names = np.load(path+'data/bio_predictor_names.npy')
conn_predictor_names = np.load(path+'data/conn_predictor_names.npy')
temp_predictor_names = np.load(path+'data/temp_predictor_names.npy')
disorders = np.load(path+'data/disorders.npy')

# parcellation
cammoun = datasets.fetch_cammoun2012()
info = pd.read_csv(cammoun['info'])
cortex = info.query('scale == "scale033" & structure == "cortex"')['id']
cortex = np.array(cortex) - 1  # python indexing
nnodes = len(cortex)
coords = utils.get_centroids(cammoun['scale033'], image_space=True)
coords = coords[cortex, :]
hemiid = np.array(info.query('scale == "scale033"')['hemisphere'])
hemiid = hemiid == 'R'
spins = stats.gen_spinsamples(coords, hemiid[cortex], seed=1234)

# colourmaps
cmap = np.genfromtxt(path+'data/colourmap.csv', delimiter=',')
cmap_seq = ListedColormap(cmap[128:, :])
cmap_blue = ListedColormap(np.flip(cmap[:128, :], axis=0))


"""
Run multilinear model and dominance analysis
"""
# set to True to run null iterations (takes time)
run_null = False

# include temporal, fc connectivity predictors if desired
predictors = [bio, conn, np.concatenate((bio, conn), axis=1)]
predictor_names = [bio_predictor_names, conn_predictor_names,
                   np.concatenate((bio_predictor_names, conn_predictor_names))]
predictor_label = ["biological", "connectivity", "bio+conn"]

Y = zscore(ct)
Y_label = disorders
cm = [cmap_seq, cmap_blue, cmap_seq]

train_metric = np.zeros([nnodes, len(Y_label), len(predictors)])
test_metric = np.zeros([nnodes, len(Y_label), len(predictors)])
bootci = np.zeros([len(Y_label), 2, len(predictors)])
bootsamp = np.zeros([len(Y_label), 1000, len(predictors)])

dominance = dict([])
dominance_null = dict([])
pvals = dict([])

for i in range(len(predictors)):

    model_metrics = dict([])

    X = predictors[i]
    X_label = predictor_names[i]

    for j in range(len(Y_label)):
        y = Y[:, j]  # disorder
        mm, _ = stats.get_dominance_stats(X, y)
        model_metrics[Y_label[j]] = mm
        # cross validate the model
        train_metric[:, j, i], test_metric[:, j, i] = \
            cv_slr_distance_dependent(X, y, coords, .75, metric='corr')
        bootci[j, 0, i], bootci[j, 1, i], bootsamp[j, :, i] = get_boot_ci(X, y, 1000)

    dominance[predictor_label[i]] = np.zeros((len(Y_label), len(X_label)))

    for j in range(len(Y_label)):
        tmp = model_metrics[Y_label[j]]
        dominance[predictor_label[i]][j, :] = tmp["total_dominance"]
    
    np.save(path+'results/dominance_'+predictor_label[i]+'.npy',
        dominance[predictor_label[i]])
        
    if run_null:
        nspins = 1000
        dominance_null[predictor_label[i]] = np.zeros((len(Y_label),
                                                       len(X_label),
                                                       nspins))
        for j in range(len(Y_label)):
            for null_i in range(nspins):
                print('predictor ', i, ', variable ', j, ', permutation ', null_i)
                ynull = Y[spins[:, null_i], j]
                mm, _ = stats.get_dominance_stats(X, ynull)
                dominance_null[predictor_label[i]][j, :, null_i] = mm['total_dominance']

        pvals[predictor_label[i]] = np.zeros(dominance[predictor_label[i]].shape)
        for row in range(pvals[predictor_label[i]].shape[0]):
            for col in range(pvals[predictor_label[i]].shape[1]):
                pvals[predictor_label[i]][row, col] = get_perm_p(dominance[predictor_label[i]][row, col],
                                                                 dominance_null[predictor_label[i]][row, col, :])
        np.save(path+'results/dominance_null_'+predictor_label[i]+'.npy',
                dominance_null[predictor_label[i]])

    # plot dominance
    plt.ion()
    plt.figure()
    sns.heatmap(dominance[predictor_label[i]], xticklabels=X_label,
                yticklabels=Y_label, cmap=cm[i], vmin=0, vmax=0.27,
                linewidths=.5)
    plt.tight_layout()
    plt.savefig(path+'figures/heatmap_dominance_' + predictor_label[i] + '.eps',
                format='eps')

# plot cross validation
fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(8, 8))
sns.violinplot(data=test_metric[:, :, 0], ax=ax1)
sns.violinplot(data=test_metric[:, :, 1], ax=ax2)
sns.violinplot(data=test_metric[:, :, 2], ax=ax3)
ax1.set(ylabel='test set correlation (bio)', ylim=(-1, 1))
ax2.set(ylabel='test set correlation (conn)', ylim=(-1, 1))
ax3.set(ylabel='test set correlation (bio+conn)', ylim=(-1, 1))
ax3.set_xticklabels(disorders, rotation=90)
plt.tight_layout()
plt.savefig(path+'figures/violin_crossval.eps',
            format='eps')

# save crossval result
np.save(path+'results/crossval_train.npy', train_metric)
np.save(path+'results/crossval_test.npy', test_metric)

# save bootstrapped confidence intervals and samp
np.save(path+'results/boot_ci.npy', bootci)
np.save(path+'results/boot_samp.npy', bootsamp)

"""
more plotting
"""
# plot r-squared of each model
bio_rsq = np.sum(dominance["biological"], axis=1)
conn_rsq = np.sum(dominance["connectivity"], axis=1)

x = np.arange(len(disorders))
width = 0.25
yerr_bio = np.array([bio_rsq - bootci[:, 0, 0], bootci[:, 1, 0] - bio_rsq])
yerr_conn = np.array([conn_rsq - bootci[:, 0, 1], bootci[:, 1, 1] - conn_rsq])

fig, ax = plt.subplots()
rects1 = ax.bar(x - width, bio_rsq, width, label='Biology',
                yerr=yerr_bio)
rects2 = ax.bar(x,         conn_rsq, width, label='Connectivity',
                yerr=yerr_conn)

ax.set_ylabel('Adjusted R^2')
ax.set_title('Biological vs Connectivity')
ax.set_xticks(x)
ax.set_xticklabels(disorders, rotation='vertical')
ax.legend()
plt.tight_layout()
plt.savefig(path+'figures/bar_bio_vs_conn.eps', format='eps')

# plot local vs global r-squared
fig, ax = plt.subplots()
ax.scatter(bio_rsq, conn_rsq, edgecolor='k', linewidth=0.3, s=70,
           c=bio_rsq-conn_rsq, cmap=ListedColormap(cmap),
           vmin=-max(abs(bio_rsq-conn_rsq)), vmax=max(abs(bio_rsq-conn_rsq)))
for i in range(len(disorders)):
    ax.text(bio_rsq[i]+0.01, conn_rsq[i]+0.01, disorders[i], fontsize=8)
ax.plot(np.arange(0, 0.8, 0.1), np.arange(0, 0.8, 0.1), 'r')
ax.set_xlim([-0.01, 0.75])
ax.set_ylim([-0.01, 0.75])
ax.set_xlabel('local biological r^2')
ax.set_ylabel('global connectivity r^2')
plt.savefig(path+'figures/scatter_bio_v_conn.eps', format='eps')

"""
PCA


size = [bio_rsq*500, conn_rsq*500]  # sizing
size[0][3] = 1
for k in range(2):
    pca = PCA(n_components=2)
    p = pca.fit_transform(dominance[predictor_label[k]])

    fig, ax = plt.subplots()
    ax.scatter(p[:, 0], p[:, 1], s=size[k], c=bio_rsq-conn_rsq, edgecolor='k',
               linewidth=0.25, cmap=ListedColormap(cmap),
               vmin=-max(abs(bio_rsq-conn_rsq)), vmax=max(abs(bio_rsq-conn_rsq)))
    for i in range(p.shape[0]):
        ax.text(p[i, 0] + 0.01, p[i, 1] + 0.01, disorders[i], fontsize=8)
    ax.set_xlabel('PC1')
    ax.set_ylabel('PC2')
    ax.set_title(predictor_label[k] + ' dominance PCA')
    plt.savefig(path+'figures/scatter_PCA_' + predictor_label[k] + '.eps',
                format='eps')
"""